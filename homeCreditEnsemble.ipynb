{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abhi/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RND CLASSIFIER.....................\n",
      "[[56234   304]\n",
      " [ 4814   151]]\n",
      "0.6702396131938747\n",
      "0.6702396131938747\n",
      "GAUSSIAN CLASSIFIER.....................\n",
      "[[ 1881 54657]\n",
      " [   66  4899]]\n",
      "0.5114906061629111\n",
      "BAGGING CLASSIFIER.....................\n",
      "[[56420   118]\n",
      " [ 4917    48]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      1.00      0.96     56538\n",
      "          1       0.29      0.01      0.02      4965\n",
      "\n",
      "avg / total       0.87      0.92      0.88     61503\n",
      "\n",
      "0.6338388939065018\n",
      "SVM CLASSIFIER.....................\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import skater\n",
    "import sklearn\n",
    "from skater.core.explanations import Interpretation\n",
    "from skater.model import InMemoryModel\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "sc = StandardScaler()\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import xgboost as xgb\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "from sklearn import preprocessing\n",
    "import matplotlib as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "link = '/home/abhi/Downloads/Kaggle/HomeCreditDefaultRisk/application_train.csv'\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "data = pd.read_csv(link)\n",
    "data['DAYS_EMPLOYED'] = data['DAYS_EMPLOYED'].replace(365243.000000,np.nan)\n",
    "data['DAYS_BIRTH']= data['DAYS_BIRTH'] / -365\n",
    "data['DAYS_ID_PUBLISH'][data['DAYS_BIRTH'] > 45.0] = data['DAYS_ID_PUBLISH'] - 17.5\n",
    "data['DAYS_ID_PUBLISH']= data['DAYS_ID_PUBLISH'] / -365\n",
    "data['DAYS_REGISTRATION'] = data['DAYS_REGISTRATION'] /-365\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "missing_col= data.columns[data.isnull().any()]\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "missing_col = list(missing_col)\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "missing_col_df = data[list(missing_col)]\n",
    "\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "non_missing_df = data[list(set(data.columns)-set(missing_col))]\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "non_missing_obj_df = non_missing_df.select_dtypes('object')\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "non_missing_obj_dummy_df = pd.get_dummies(non_missing_obj_df)  # add--------------------------------\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "non_missing_numerical_df = non_missing_df[list(set(non_missing_df.columns)-set(non_missing_obj_df.columns))] # add-\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "df_obj = missing_col_df.select_dtypes('object')\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "df_obj_dummy = pd.get_dummies(df_obj) # add -----------------------------------------\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "data_obj_col = set(df_obj.columns)\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "data_num_col = set(missing_col_df.columns) - data_obj_col\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "data_num_col = list(data_num_col)\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "df_numerical = missing_col_df[data_num_col]\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "df_numerical_notnan = df_numerical.fillna(0) # add-----------------------------------------\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "df_numerical_nan = df_numerical - df_numerical\n",
    "\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "\n",
    "df_numerical_nan = df_numerical_nan.replace(np.nan, 1) # add-------------------------------------\n",
    "\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "\n",
    "df_numerical_nan_col = map(str.lower,list(df_numerical_nan.columns))\n",
    "\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "\n",
    "df_numerical_nan.columns = df_numerical_nan_col\n",
    "\n",
    "\n",
    "# In[22]:\n",
    "\n",
    "\n",
    "df_numerical_final = pd.concat([non_missing_obj_dummy_df, non_missing_numerical_df,\n",
    "                                df_obj_dummy, df_numerical_notnan,df_numerical_nan], axis=1) \n",
    "\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[24]:\n",
    "\n",
    "\n",
    "# DATA SPLIT\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(df_numerical_final, df_numerical_final['TARGET']):\n",
    "    train_set = df_numerical_final.loc[train_index]\n",
    "    test_set = df_numerical_final.loc[test_index]\n",
    "\n",
    "X_train = train_set.drop(['TARGET'],axis=1)\n",
    "y_train = train_set['TARGET']\n",
    "X_test = test_set.drop(['TARGET'],axis=1)\n",
    "\n",
    "y_test = test_set['TARGET']\n",
    "\n",
    "\n",
    "\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "y_test = y_test.values\n",
    "y_train = y_train.values\n",
    "\n",
    "# In[28]:\n",
    "print('RND CLASSIFIER.....................')\n",
    "\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=15, min_samples_leaf=2,\n",
    "                                 min_samples_split=2, class_weight='balanced',random_state=0)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "preds_rnd = rnd_clf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, preds_rnd))\n",
    "\n",
    "\n",
    "# In[29]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "print(roc_auc_score(y_test, rnd_clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "\n",
    "# In[31]:\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "print(roc_auc_score(y_test, rnd_clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "\n",
    "# In[32]:\n",
    "print('GAUSSIAN CLASSIFIER.....................')\n",
    "\n",
    "\n",
    "gnb_clf = GaussianNB()\n",
    "gnb_clf.fit(X_train, y_train)\n",
    "preds_gnb = gnb_clf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, preds_gnb))\n",
    "\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "print(roc_auc_score(y_test, gnb_clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "\n",
    "# In[34]:\n",
    "\n",
    "print('BAGGING CLASSIFIER.....................')\n",
    "\n",
    "\n",
    "# In[39]:\n",
    "\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "DecisionTreeClassifier(), n_estimators=10,\n",
    "max_samples=0.8 ,max_features=1.0,bootstrap_features=True,\n",
    "bootstrap=False,\n",
    "n_jobs=-1\n",
    ")\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "bag_clf.fit(X_train, y_train)\n",
    "preds_bag = bag_clf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, preds_bag))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, preds_bag))\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "print(roc_auc_score(y_test, bag_clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "\n",
    "print('SVM CLASSIFIER.....................')\n",
    "\n",
    "\n",
    "\n",
    "polynomial_svm_clf =  SVC(C=20, probability=True, degree=2)\n",
    "polynomial_svm_clf.fit(X_train,y_train)\n",
    "preds_svm = polynomial_svm_clf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, preds_svm))\n",
    "print(classification_report(y_test, preds_svm))\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "print(roc_auc_score(y_test,polynomial_svm_clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "print('XGBOOST CLASSIFIER.....................')\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "print('LDA CLASSIFIER.....................')\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "lda_clf = LinearDiscriminantAnalysis(n_components = 4)\n",
    "lda_clf.fit(X_train, y_train)\n",
    "preds_lda = lda_clf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, preds_lda))\n",
    "print(classification_report(y_test, preds_lda))\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "print(roc_auc_score(y_test,lda_clf.predict_proba(X_test)[:,1]))\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "print('.................FINAL VOTING CLASSIFIER.....................')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "voting_clf = VotingClassifier(\n",
    "estimators=[('bag_clf', bag_clf), ('polynomial_svm_clf',polynomial_svm_clf),\n",
    "            ('rnd_clf', rnd_clf), ('xgb_clf', xgb_clf), ('gnb_clf', gnb_clf), ('lda_clf', lda_clf)],\n",
    "    weights=[3,3,4,3,4,4],\n",
    "voting='soft'\n",
    ")\n",
    "voting_clf.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "preds_vtg = voting_clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, preds_vtg))\n",
    "print(classification_report(y_test, preds_vtg))\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "print(roc_auc_score(y_test,voting_clf.predict_proba(X_test)[:,1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
